{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":99687,"status":"ok","timestamp":1742367680890,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"hmO7NUU-_lox","outputId":"06562b78-f29a-46bf-f406-fa24651d935f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n"]}],"source":["!pip install torch torchvision torchaudio\n","!pip install pycocotools"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":23999,"status":"ok","timestamp":1742367704882,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"d-PEdlRawY1G","outputId":"79c07ff2-94d5-42d4-a4a6-276bb6e6cb5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyyaml==5.1\n","  Downloading PyYAML-5.1.tar.gz (274 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/274.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m266.2/274.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Cloning into 'detectron2'...\n","remote: Enumerating objects: 15837, done.\u001b[K\n","remote: Counting objects: 100% (66/66), done.\u001b[K\n","remote: Compressing objects: 100% (54/54), done.\u001b[K\n","remote: Total 15837 (delta 30), reused 12 (delta 12), pack-reused 15771 (from 2)\u001b[K\n","Receiving objects: 100% (15837/15837), 6.40 MiB | 9.81 MiB/s, done.\n","Resolving deltas: 100% (11532/11532), done.\n","Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (11.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (2.0.8)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (2.5.0)\n","Collecting yacs>=0.1.8\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (3.1.1)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Collecting fvcore<0.1.6,>=0.1.5\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting iopath<0.1.10,>=0.1.7\n","  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n","Collecting omegaconf<2.4,>=2.1\n","  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting hydra-core>=1.1\n","  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n","Collecting black\n","  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (24.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs>=0.1.8) (6.0.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n","Collecting portalocker (from iopath<0.1.10,>=0.1.7)\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4,>=2.1)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black) (8.1.8)\n","Collecting mypy-extensions>=0.4.3 (from black)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting pathspec>=0.9.0 (from black)\n","  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black) (4.3.6)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: fvcore, antlr4-python3-runtime\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=4d92b6f6243ebf3b441f8e31088012da6c964dff535e028a2ff417598d577d94\n","  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=dd74932d45a780e603228297b37cbdb2495e99b688432eaea11e88bc926bb6d5\n","  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n","Successfully built fvcore antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore\n","Successfully installed antlr4-python3-runtime-4.9.3 black-25.1.0 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.1.1 yacs-0.1.8\n"]}],"source":["!python -m pip install pyyaml==5.1\n","import sys, os, distutils.core\n","\n","!git clone 'https://github.com/facebookresearch/detectron2'\n","dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n","!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n","sys.path.insert(0, os.path.abspath('./detectron2'))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1742367705306,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"ZI6a6Da9w4gt","outputId":"08e44b2e-4448-4522-dbff-7ee3ad390af9"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n","torch:  2.6 ; cuda:  cu124\n","detectron2: 0.6\n"]}],"source":["import torch, detectron2\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21966,"status":"ok","timestamp":1742367727264,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"xB9-xmGz1Ng9","outputId":"a9049725-8205-4b1a-e172-520d7aba88a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set main directory\n","ROOT_DIR = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)\"\n","\n","# Define paths for saving outputs\n","MODEL_DIR = os.path.join(ROOT_DIR, \"Model\")\n","FINAL_IMAGES_DIR = os.path.join(ROOT_DIR, \"Final images\")\n","COMBINED_DIR = os.path.join(ROOT_DIR, \"Combined\")\n","\n","# Create directories if not exist\n","for dir_path in [MODEL_DIR, FINAL_IMAGES_DIR, COMBINED_DIR]:\n","    os.makedirs(dir_path, exist_ok=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7293,"status":"ok","timestamp":1742367840133,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"LpaC7tfM5sVV","outputId":"d17e7423-f033-4049-f7cd-551d03f07059"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique category IDs in train: {0}\n","Unique category IDs in valid: {0}\n","Unique category IDs in test: {0}\n"]}],"source":["import json\n","import os\n","from detectron2.structures import BoxMode\n","\n","# Define dataset paths\n","DATASET_DIR = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)\"\n","ANNOTATIONS = {\n","    \"train\": os.path.join(DATASET_DIR, \"train_annotations.coco.json\"),\n","    \"valid\": os.path.join(DATASET_DIR, \"valid_annotations.coco.json\"),\n","    \"test\": os.path.join(DATASET_DIR, \"test_annotations.coco.json\"),\n","}\n","\n","def load_coco_json(json_file, image_dir):\n","    with open(json_file) as f:\n","        coco_data = json.load(f)\n","\n","    dataset_dicts = []\n","    for image in coco_data[\"images\"]:\n","        record = {\n","            \"file_name\": os.path.join(image_dir, image[\"file_name\"]),\n","            \"image_id\": image[\"id\"],\n","            \"height\": image[\"height\"],\n","            \"width\": image[\"width\"],\n","            \"annotations\": [],\n","        }\n","\n","        for ann in coco_data[\"annotations\"]:\n","            if ann[\"image_id\"] == image[\"id\"]:\n","                new_category_id = 0  # Ensure category ID is 0 for all annotations\n","\n","                record[\"annotations\"].append({\n","                    \"bbox\": ann[\"bbox\"],\n","                    \"bbox_mode\": BoxMode.XYWH_ABS,\n","                    \"category_id\": new_category_id,\n","                    \"segmentation\": ann[\"segmentation\"],\n","                })\n","\n","        dataset_dicts.append(record)\n","\n","    return dataset_dicts\n","\n","# Register dataset properly\n","from detectron2.data import DatasetCatalog, MetadataCatalog\n","\n","for d in [\"train\", \"valid\", \"test\"]:\n","    dataset_name = \"tree_\" + d\n","    try:\n","        DatasetCatalog.remove(dataset_name)  # Ensure clean registration\n","    except KeyError:\n","        pass  # Ignore if the dataset isn't registered yet\n","\n","    DatasetCatalog.register(dataset_name, lambda d=d: load_coco_json(\n","        ANNOTATIONS[d], os.path.join(DATASET_DIR, d)\n","    ))\n","    MetadataCatalog.get(dataset_name).set(thing_classes=[\"Tree\"])\n","\n","# Verify dataset is correctly loaded\n","for d in [\"train\", \"valid\", \"test\"]:\n","    dataset_dicts = DatasetCatalog.get(\"tree_\" + d)\n","    category_ids = set(ann[\"category_id\"] for img in dataset_dicts for ann in img[\"annotations\"])\n","    print(f\"Unique category IDs in {d}: {category_ids}\")  # Expected: {0}"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"SEHxLwhcA0Kd","executionInfo":{"status":"ok","timestamp":1742372492984,"user_tz":-330,"elapsed":4647826,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"}},"outputId":"b6159a2b-86b0-4584-f1dc-08897e571c1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[03/19 07:04:05 d2.engine.defaults]: Model:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","[03/19 07:04:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomFlip(), RandomFlip(horizontal=False, vertical=True), RandomRotation(angle=[-10, 10]), RandomBrightness(intensity_min=0.8, intensity_max=1.2), RandomContrast(intensity_min=0.8, intensity_max=1.2), RandomSaturation(intensity_min=0.8, intensity_max=1.2), RandomExtent(scale_range=(0.8, 1.2), shift_range=(0.1, 0.1))]\n","[03/19 07:04:05 d2.data.build]: Removed 0 images with no usable annotations. 75 images left.\n","[03/19 07:04:05 d2.data.build]: Distribution of instances among all 1 categories:\n","|  category  | #instances   |\n","|:----------:|:-------------|\n","|    Tree    | 1808         |\n","|            |              |\n","[03/19 07:04:05 d2.data.build]: Using training sampler TrainingSampler\n","[03/19 07:04:05 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/19 07:04:05 d2.data.common]: Serializing 75 elements to byte tensors and concatenating them all ...\n","[03/19 07:04:05 d2.data.common]: Serialized dataset takes 0.54 MiB\n","[03/19 07:04:05 d2.data.build]: Making batched data loader with batch_size=8\n","[03/19 07:04:05 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","model_final_f10217.pkl: 178MB [00:01, 120MB/s]                           \n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n","roi_heads.box_predictor.bbox_pred.{bias, weight}\n","roi_heads.box_predictor.cls_score.{bias, weight}\n","roi_heads.mask_head.predictor.{bias, weight}\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 07:04:07 d2.engine.train_loop]: Starting training from iteration 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 07:04:55 d2.utils.events]:  eta: 1:06:54  iter: 19  total_loss: 3.064  loss_cls: 0.7079  loss_box_reg: 0.6448  loss_mask: 0.6873  loss_rpn_cls: 0.9047  loss_rpn_loc: 0.1779    time: 2.1130  last_time: 2.3917  data_time: 0.1501  last_data_time: 0.0570   lr: 4.7702e-05  max_mem: 8862M\n","[03/19 07:05:47 d2.utils.events]:  eta: 1:08:01  iter: 39  total_loss: 2.313  loss_cls: 0.5585  loss_box_reg: 0.7543  loss_mask: 0.6449  loss_rpn_cls: 0.2116  loss_rpn_loc: 0.1606    time: 2.1612  last_time: 2.6602  data_time: 0.0613  last_data_time: 0.1057   lr: 9.7652e-05  max_mem: 8862M\n","[03/19 07:06:32 d2.utils.events]:  eta: 1:09:26  iter: 59  total_loss: 2.13  loss_cls: 0.4947  loss_box_reg: 0.769  loss_mask: 0.5649  loss_rpn_cls: 0.1632  loss_rpn_loc: 0.1575    time: 2.1956  last_time: 2.1833  data_time: 0.0637  last_data_time: 0.0749   lr: 0.0001476  max_mem: 8862M\n","[03/19 07:07:18 d2.utils.events]:  eta: 1:09:41  iter: 79  total_loss: 2.007  loss_cls: 0.4517  loss_box_reg: 0.7742  loss_mask: 0.4825  loss_rpn_cls: 0.1288  loss_rpn_loc: 0.1628    time: 2.2212  last_time: 2.1619  data_time: 0.0622  last_data_time: 0.0682   lr: 0.00019755  max_mem: 8862M\n","[03/19 07:08:04 d2.utils.events]:  eta: 1:09:04  iter: 99  total_loss: 1.864  loss_cls: 0.4135  loss_box_reg: 0.7704  loss_mask: 0.4138  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1648    time: 2.2321  last_time: 2.2331  data_time: 0.0516  last_data_time: 0.0429   lr: 0.0002475  max_mem: 8862M\n","[03/19 07:08:50 d2.utils.events]:  eta: 1:08:32  iter: 119  total_loss: 1.692  loss_cls: 0.3855  loss_box_reg: 0.7136  loss_mask: 0.3389  loss_rpn_cls: 0.09213  loss_rpn_loc: 0.1498    time: 2.2430  last_time: 2.2569  data_time: 0.0648  last_data_time: 0.0697   lr: 0.00025  max_mem: 8863M\n","[03/19 07:09:35 d2.utils.events]:  eta: 1:08:04  iter: 139  total_loss: 1.562  loss_cls: 0.3523  loss_box_reg: 0.647  loss_mask: 0.3123  loss_rpn_cls: 0.08587  loss_rpn_loc: 0.1498    time: 2.2479  last_time: 2.6166  data_time: 0.0601  last_data_time: 0.0328   lr: 0.00025  max_mem: 8863M\n","[03/19 07:10:21 d2.utils.events]:  eta: 1:07:42  iter: 159  total_loss: 1.486  loss_cls: 0.3559  loss_box_reg: 0.5953  loss_mask: 0.316  loss_rpn_cls: 0.06803  loss_rpn_loc: 0.1507    time: 2.2552  last_time: 2.3098  data_time: 0.0520  last_data_time: 0.0441   lr: 0.00025  max_mem: 8863M\n","[03/19 07:11:07 d2.utils.events]:  eta: 1:07:02  iter: 179  total_loss: 1.437  loss_cls: 0.3395  loss_box_reg: 0.5726  loss_mask: 0.3085  loss_rpn_cls: 0.07654  loss_rpn_loc: 0.1519    time: 2.2585  last_time: 2.3092  data_time: 0.0595  last_data_time: 0.0436   lr: 0.00025  max_mem: 8863M\n","[03/19 07:11:54 d2.utils.events]:  eta: 1:06:38  iter: 199  total_loss: 1.419  loss_cls: 0.3436  loss_box_reg: 0.5509  loss_mask: 0.308  loss_rpn_cls: 0.06427  loss_rpn_loc: 0.1442    time: 2.2672  last_time: 2.2951  data_time: 0.0680  last_data_time: 0.0704   lr: 0.00025  max_mem: 8863M\n","[03/19 07:12:40 d2.utils.events]:  eta: 1:05:53  iter: 219  total_loss: 1.421  loss_cls: 0.3403  loss_box_reg: 0.5525  loss_mask: 0.3044  loss_rpn_cls: 0.06801  loss_rpn_loc: 0.1417    time: 2.2697  last_time: 2.2829  data_time: 0.0663  last_data_time: 0.0370   lr: 0.00025  max_mem: 8863M\n","[03/19 07:13:26 d2.utils.events]:  eta: 1:05:13  iter: 239  total_loss: 1.431  loss_cls: 0.3368  loss_box_reg: 0.5482  loss_mask: 0.3053  loss_rpn_cls: 0.06368  loss_rpn_loc: 0.1468    time: 2.2746  last_time: 2.3055  data_time: 0.0569  last_data_time: 0.0652   lr: 0.00025  max_mem: 8863M\n","[03/19 07:13:49 d2.data.build]: Distribution of instances among all 1 categories:\n","|  category  | #instances   |\n","|:----------:|:-------------|\n","|    Tree    | 154          |\n","|            |              |\n","[03/19 07:13:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[03/19 07:13:49 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/19 07:13:49 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n","[03/19 07:13:49 d2.data.common]: Serialized dataset takes 0.04 MiB\n","[03/19 07:13:49 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n","WARNING [03/19 07:13:49 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[03/19 07:13:49 d2.evaluation.coco_evaluation]: Trying to convert 'tree_valid' to COCO format ...\n","[03/19 07:13:49 d2.data.datasets.coco]: Converting annotations of dataset 'tree_valid' to COCO format ...)\n","[03/19 07:13:49 d2.data.datasets.coco]: Converting dataset dicts into COCO format\n","[03/19 07:13:49 d2.data.datasets.coco]: Conversion finished, #images: 5, #annotations: 154\n","[03/19 07:13:49 d2.data.datasets.coco]: Caching COCO format annotations at '/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/inference/tree_valid_coco_format.json' ...\n","[03/19 07:13:49 d2.evaluation.evaluator]: Start inference on 5 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 07:13:51 d2.evaluation.evaluator]: Total inference time: 0:00:00.246197 (0.246197 s / iter per device, on 1 devices)\n","[03/19 07:13:51 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:00 (0.092391 s / iter per device, on 1 devices)\n","[03/19 07:13:51 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[03/19 07:13:51 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/inference/coco_instances_results.json\n","[03/19 07:13:51 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.10s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.317\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.175\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.563\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:13:51 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 33.293 | 67.576 | 31.693 | 25.966 | 41.977 |  nan  |\n","[03/19 07:13:51 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.10s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.708\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.166\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.357\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.496\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:13:52 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 32.002 | 70.775 | 21.153 | 20.913 | 41.152 |  nan  |\n","[03/19 07:13:52 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[03/19 07:13:52 d2.engine.defaults]: Evaluation results for tree_valid in csv format:\n","[03/19 07:13:52 d2.evaluation.testing]: copypaste: Task: bbox\n","[03/19 07:13:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:13:52 d2.evaluation.testing]: copypaste: 33.2927,67.5759,31.6929,25.9659,41.9772,nan\n","[03/19 07:13:52 d2.evaluation.testing]: copypaste: Task: segm\n","[03/19 07:13:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:13:52 d2.evaluation.testing]: copypaste: 32.0022,70.7753,21.1533,20.9133,41.1523,nan\n","[03/19 07:14:14 d2.utils.events]:  eta: 1:04:32  iter: 259  total_loss: 1.368  loss_cls: 0.3306  loss_box_reg: 0.5324  loss_mask: 0.3007  loss_rpn_cls: 0.05459  loss_rpn_loc: 0.1377    time: 2.2750  last_time: 2.1970  data_time: 0.0558  last_data_time: 0.0455   lr: 0.00025  max_mem: 8863M\n","[03/19 07:15:01 d2.utils.events]:  eta: 1:03:51  iter: 279  total_loss: 1.38  loss_cls: 0.3283  loss_box_reg: 0.5364  loss_mask: 0.3002  loss_rpn_cls: 0.06065  loss_rpn_loc: 0.1348    time: 2.2788  last_time: 2.0324  data_time: 0.0600  last_data_time: 0.0754   lr: 0.00025  max_mem: 8863M\n","[03/19 07:15:47 d2.utils.events]:  eta: 1:03:14  iter: 299  total_loss: 1.336  loss_cls: 0.3236  loss_box_reg: 0.5175  loss_mask: 0.3035  loss_rpn_cls: 0.05219  loss_rpn_loc: 0.1276    time: 2.2821  last_time: 2.5290  data_time: 0.0551  last_data_time: 0.0511   lr: 0.00025  max_mem: 8863M\n","[03/19 07:16:34 d2.utils.events]:  eta: 1:02:33  iter: 319  total_loss: 1.341  loss_cls: 0.317  loss_box_reg: 0.5177  loss_mask: 0.2943  loss_rpn_cls: 0.06036  loss_rpn_loc: 0.1351    time: 2.2856  last_time: 2.3353  data_time: 0.0678  last_data_time: 0.0253   lr: 0.00025  max_mem: 8863M\n","[03/19 07:17:19 d2.utils.events]:  eta: 1:01:45  iter: 339  total_loss: 1.294  loss_cls: 0.3139  loss_box_reg: 0.5051  loss_mask: 0.2954  loss_rpn_cls: 0.05301  loss_rpn_loc: 0.1377    time: 2.2831  last_time: 2.1161  data_time: 0.0575  last_data_time: 0.0737   lr: 0.00025  max_mem: 8863M\n","[03/19 07:18:05 d2.utils.events]:  eta: 1:00:58  iter: 359  total_loss: 1.357  loss_cls: 0.3326  loss_box_reg: 0.5283  loss_mask: 0.2961  loss_rpn_cls: 0.05486  loss_rpn_loc: 0.1446    time: 2.2835  last_time: 2.6094  data_time: 0.0521  last_data_time: 0.0211   lr: 0.00025  max_mem: 8863M\n","[03/19 07:18:51 d2.utils.events]:  eta: 1:00:17  iter: 379  total_loss: 1.31  loss_cls: 0.3089  loss_box_reg: 0.5075  loss_mask: 0.2902  loss_rpn_cls: 0.0485  loss_rpn_loc: 0.1338    time: 2.2846  last_time: 2.3235  data_time: 0.0588  last_data_time: 0.0511   lr: 0.00025  max_mem: 8863M\n","[03/19 07:19:37 d2.utils.events]:  eta: 0:59:31  iter: 399  total_loss: 1.314  loss_cls: 0.3186  loss_box_reg: 0.5142  loss_mask: 0.2922  loss_rpn_cls: 0.05358  loss_rpn_loc: 0.1348    time: 2.2843  last_time: 2.1902  data_time: 0.0516  last_data_time: 0.0264   lr: 0.00025  max_mem: 8863M\n","[03/19 07:20:23 d2.utils.events]:  eta: 0:58:48  iter: 419  total_loss: 1.325  loss_cls: 0.3152  loss_box_reg: 0.5129  loss_mask: 0.2915  loss_rpn_cls: 0.05327  loss_rpn_loc: 0.1365    time: 2.2863  last_time: 2.2224  data_time: 0.0577  last_data_time: 0.0660   lr: 0.00025  max_mem: 8863M\n","[03/19 07:21:09 d2.utils.events]:  eta: 0:58:03  iter: 439  total_loss: 1.302  loss_cls: 0.3196  loss_box_reg: 0.5021  loss_mask: 0.291  loss_rpn_cls: 0.04889  loss_rpn_loc: 0.1309    time: 2.2865  last_time: 2.1850  data_time: 0.0609  last_data_time: 0.0581   lr: 0.00025  max_mem: 8863M\n","[03/19 07:21:55 d2.utils.events]:  eta: 0:57:24  iter: 459  total_loss: 1.304  loss_cls: 0.3246  loss_box_reg: 0.5142  loss_mask: 0.2924  loss_rpn_cls: 0.04842  loss_rpn_loc: 0.1347    time: 2.2874  last_time: 2.5129  data_time: 0.0511  last_data_time: 0.1097   lr: 0.00025  max_mem: 8863M\n","[03/19 07:22:40 d2.utils.events]:  eta: 0:56:36  iter: 479  total_loss: 1.297  loss_cls: 0.3116  loss_box_reg: 0.5078  loss_mask: 0.2892  loss_rpn_cls: 0.04753  loss_rpn_loc: 0.1271    time: 2.2859  last_time: 2.1868  data_time: 0.0656  last_data_time: 0.0230   lr: 0.00025  max_mem: 8863M\n","[03/19 07:23:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[03/19 07:23:27 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/19 07:23:27 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n","[03/19 07:23:27 d2.data.common]: Serialized dataset takes 0.04 MiB\n","[03/19 07:23:27 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n","WARNING [03/19 07:23:27 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[03/19 07:23:27 d2.evaluation.evaluator]: Start inference on 5 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 07:23:28 d2.evaluation.evaluator]: Total inference time: 0:00:00.261631 (0.261631 s / iter per device, on 1 devices)\n","[03/19 07:23:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:00 (0.095528 s / iter per device, on 1 devices)\n","[03/19 07:23:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[03/19 07:23:28 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/inference/coco_instances_results.json\n","[03/19 07:23:28 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.10s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.735\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.293\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.371\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.557\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:23:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 35.021 | 73.512 | 32.732 | 29.343 | 42.867 |  nan  |\n","[03/19 07:23:28 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.10s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.740\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.237\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.381\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:23:29 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 34.645 | 73.951 | 28.280 | 23.655 | 43.926 |  nan  |\n","[03/19 07:23:29 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[03/19 07:23:29 d2.engine.defaults]: Evaluation results for tree_valid in csv format:\n","[03/19 07:23:29 d2.evaluation.testing]: copypaste: Task: bbox\n","[03/19 07:23:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:23:29 d2.evaluation.testing]: copypaste: 35.0208,73.5120,32.7320,29.3433,42.8672,nan\n","[03/19 07:23:29 d2.evaluation.testing]: copypaste: Task: segm\n","[03/19 07:23:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:23:29 d2.evaluation.testing]: copypaste: 34.6445,73.9512,28.2799,23.6545,43.9264,nan\n","[03/19 07:23:29 d2.utils.events]:  eta: 0:56:02  iter: 499  total_loss: 1.271  loss_cls: 0.3038  loss_box_reg: 0.5067  loss_mask: 0.2877  loss_rpn_cls: 0.05076  loss_rpn_loc: 0.1403    time: 2.2886  last_time: 2.6695  data_time: 0.0619  last_data_time: 0.0535   lr: 0.00025  max_mem: 8864M\n","[03/19 07:24:15 d2.utils.events]:  eta: 0:55:17  iter: 519  total_loss: 1.285  loss_cls: 0.3101  loss_box_reg: 0.5048  loss_mask: 0.2927  loss_rpn_cls: 0.04545  loss_rpn_loc: 0.1333    time: 2.2889  last_time: 2.2240  data_time: 0.0710  last_data_time: 0.0907   lr: 0.00025  max_mem: 8864M\n","[03/19 07:25:01 d2.utils.events]:  eta: 0:54:37  iter: 539  total_loss: 1.291  loss_cls: 0.3126  loss_box_reg: 0.5052  loss_mask: 0.2875  loss_rpn_cls: 0.04692  loss_rpn_loc: 0.1349    time: 2.2902  last_time: 2.1360  data_time: 0.0658  last_data_time: 0.0709   lr: 0.00025  max_mem: 8864M\n","[03/19 07:25:47 d2.utils.events]:  eta: 0:53:51  iter: 559  total_loss: 1.258  loss_cls: 0.2992  loss_box_reg: 0.4976  loss_mask: 0.2898  loss_rpn_cls: 0.04825  loss_rpn_loc: 0.1277    time: 2.2905  last_time: 2.2916  data_time: 0.0622  last_data_time: 0.0262   lr: 0.00025  max_mem: 8864M\n","[03/19 07:26:34 d2.utils.events]:  eta: 0:53:08  iter: 579  total_loss: 1.261  loss_cls: 0.3105  loss_box_reg: 0.5078  loss_mask: 0.2821  loss_rpn_cls: 0.0467  loss_rpn_loc: 0.1254    time: 2.2917  last_time: 2.3273  data_time: 0.0542  last_data_time: 0.0248   lr: 0.00025  max_mem: 8864M\n","[03/19 07:27:19 d2.utils.events]:  eta: 0:52:23  iter: 599  total_loss: 1.268  loss_cls: 0.3023  loss_box_reg: 0.5058  loss_mask: 0.2869  loss_rpn_cls: 0.04777  loss_rpn_loc: 0.1209    time: 2.2919  last_time: 2.6594  data_time: 0.0582  last_data_time: 0.0279   lr: 0.00025  max_mem: 8864M\n","[03/19 07:28:05 d2.utils.events]:  eta: 0:51:38  iter: 619  total_loss: 1.272  loss_cls: 0.3005  loss_box_reg: 0.5074  loss_mask: 0.2892  loss_rpn_cls: 0.04488  loss_rpn_loc: 0.1281    time: 2.2911  last_time: 2.1474  data_time: 0.0585  last_data_time: 0.0411   lr: 0.00025  max_mem: 8864M\n","[03/19 07:28:51 d2.utils.events]:  eta: 0:50:53  iter: 639  total_loss: 1.263  loss_cls: 0.3049  loss_box_reg: 0.4933  loss_mask: 0.2858  loss_rpn_cls: 0.04783  loss_rpn_loc: 0.1294    time: 2.2919  last_time: 2.6144  data_time: 0.0572  last_data_time: 0.0270   lr: 0.00025  max_mem: 8864M\n","[03/19 07:29:37 d2.utils.events]:  eta: 0:50:08  iter: 659  total_loss: 1.267  loss_cls: 0.3049  loss_box_reg: 0.5077  loss_mask: 0.2836  loss_rpn_cls: 0.04512  loss_rpn_loc: 0.1207    time: 2.2920  last_time: 2.1432  data_time: 0.0663  last_data_time: 0.0661   lr: 0.00025  max_mem: 8864M\n","[03/19 07:30:23 d2.utils.events]:  eta: 0:49:23  iter: 679  total_loss: 1.25  loss_cls: 0.3062  loss_box_reg: 0.4942  loss_mask: 0.2847  loss_rpn_cls: 0.04118  loss_rpn_loc: 0.1226    time: 2.2921  last_time: 2.1638  data_time: 0.0621  last_data_time: 0.0606   lr: 0.00025  max_mem: 8864M\n","[03/19 07:31:10 d2.utils.events]:  eta: 0:48:39  iter: 699  total_loss: 1.248  loss_cls: 0.2931  loss_box_reg: 0.4979  loss_mask: 0.2828  loss_rpn_cls: 0.04469  loss_rpn_loc: 0.131    time: 2.2937  last_time: 2.3466  data_time: 0.0654  last_data_time: 0.0531   lr: 0.00025  max_mem: 8864M\n","[03/19 07:31:55 d2.utils.events]:  eta: 0:47:54  iter: 719  total_loss: 1.288  loss_cls: 0.3046  loss_box_reg: 0.4949  loss_mask: 0.2879  loss_rpn_cls: 0.05426  loss_rpn_loc: 0.144    time: 2.2928  last_time: 2.1559  data_time: 0.0578  last_data_time: 0.0827   lr: 0.00025  max_mem: 8864M\n","[03/19 07:32:41 d2.utils.events]:  eta: 0:47:09  iter: 739  total_loss: 1.223  loss_cls: 0.3068  loss_box_reg: 0.4947  loss_mask: 0.2794  loss_rpn_cls: 0.03908  loss_rpn_loc: 0.1191    time: 2.2932  last_time: 2.5746  data_time: 0.0566  last_data_time: 0.0311   lr: 0.00025  max_mem: 8864M\n","[03/19 07:33:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[03/19 07:33:04 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/19 07:33:04 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n","[03/19 07:33:04 d2.data.common]: Serialized dataset takes 0.04 MiB\n","[03/19 07:33:04 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n","WARNING [03/19 07:33:04 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[03/19 07:33:04 d2.evaluation.evaluator]: Start inference on 5 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 07:33:05 d2.evaluation.evaluator]: Total inference time: 0:00:00.311044 (0.311044 s / iter per device, on 1 devices)\n","[03/19 07:33:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:00 (0.097214 s / iter per device, on 1 devices)\n","[03/19 07:33:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[03/19 07:33:06 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/inference/coco_instances_results.json\n","[03/19 07:33:06 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.18s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.348\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.182\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.371\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:33:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 36.294 | 72.885 | 34.755 | 29.233 | 45.148 |  nan  |\n","[03/19 07:33:06 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.20s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.297\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.183\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.384\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:33:06 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 36.248 | 76.926 | 29.715 | 23.171 | 46.550 |  nan  |\n","[03/19 07:33:06 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[03/19 07:33:06 d2.engine.defaults]: Evaluation results for tree_valid in csv format:\n","[03/19 07:33:06 d2.evaluation.testing]: copypaste: Task: bbox\n","[03/19 07:33:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:33:06 d2.evaluation.testing]: copypaste: 36.2942,72.8851,34.7551,29.2330,45.1476,nan\n","[03/19 07:33:06 d2.evaluation.testing]: copypaste: Task: segm\n","[03/19 07:33:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:33:06 d2.evaluation.testing]: copypaste: 36.2483,76.9263,29.7148,23.1705,46.5495,nan\n","[03/19 07:33:29 d2.utils.events]:  eta: 0:46:24  iter: 759  total_loss: 1.248  loss_cls: 0.3001  loss_box_reg: 0.4963  loss_mask: 0.2833  loss_rpn_cls: 0.03598  loss_rpn_loc: 0.1256    time: 2.2940  last_time: 2.3696  data_time: 0.0685  last_data_time: 0.0522   lr: 0.00025  max_mem: 8864M\n","[03/19 07:34:16 d2.utils.events]:  eta: 0:45:39  iter: 779  total_loss: 1.23  loss_cls: 0.2999  loss_box_reg: 0.4838  loss_mask: 0.2801  loss_rpn_cls: 0.0356  loss_rpn_loc: 0.1229    time: 2.2949  last_time: 2.6369  data_time: 0.0797  last_data_time: 0.0744   lr: 0.00025  max_mem: 8864M\n","[03/19 07:35:01 d2.utils.events]:  eta: 0:44:54  iter: 799  total_loss: 1.238  loss_cls: 0.2973  loss_box_reg: 0.4978  loss_mask: 0.2821  loss_rpn_cls: 0.04103  loss_rpn_loc: 0.1291    time: 2.2944  last_time: 2.2696  data_time: 0.0605  last_data_time: 0.0244   lr: 0.00025  max_mem: 8864M\n","[03/19 07:35:47 d2.utils.events]:  eta: 0:44:09  iter: 819  total_loss: 1.226  loss_cls: 0.3027  loss_box_reg: 0.4869  loss_mask: 0.2831  loss_rpn_cls: 0.04139  loss_rpn_loc: 0.1255    time: 2.2935  last_time: 2.2334  data_time: 0.0614  last_data_time: 0.0460   lr: 0.00025  max_mem: 8864M\n","[03/19 07:36:33 d2.utils.events]:  eta: 0:43:24  iter: 839  total_loss: 1.24  loss_cls: 0.2988  loss_box_reg: 0.4811  loss_mask: 0.2772  loss_rpn_cls: 0.04333  loss_rpn_loc: 0.1277    time: 2.2939  last_time: 2.5553  data_time: 0.0531  last_data_time: 0.0774   lr: 0.00025  max_mem: 8864M\n","[03/19 07:37:18 d2.utils.events]:  eta: 0:42:39  iter: 859  total_loss: 1.211  loss_cls: 0.293  loss_box_reg: 0.4852  loss_mask: 0.2804  loss_rpn_cls: 0.0396  loss_rpn_loc: 0.1083    time: 2.2934  last_time: 2.1898  data_time: 0.0565  last_data_time: 0.0526   lr: 0.00025  max_mem: 8864M\n","[03/19 07:38:05 d2.utils.events]:  eta: 0:41:55  iter: 879  total_loss: 1.242  loss_cls: 0.2983  loss_box_reg: 0.4887  loss_mask: 0.2746  loss_rpn_cls: 0.04057  loss_rpn_loc: 0.1304    time: 2.2945  last_time: 2.2596  data_time: 0.0577  last_data_time: 0.0639   lr: 0.00025  max_mem: 8864M\n","[03/19 07:38:51 d2.utils.events]:  eta: 0:41:10  iter: 899  total_loss: 1.234  loss_cls: 0.2924  loss_box_reg: 0.4815  loss_mask: 0.2822  loss_rpn_cls: 0.0412  loss_rpn_loc: 0.1311    time: 2.2948  last_time: 2.1206  data_time: 0.0481  last_data_time: 0.0507   lr: 0.00025  max_mem: 8864M\n","[03/19 07:39:38 d2.utils.events]:  eta: 0:40:26  iter: 919  total_loss: 1.209  loss_cls: 0.2968  loss_box_reg: 0.4801  loss_mask: 0.2806  loss_rpn_cls: 0.03708  loss_rpn_loc: 0.1201    time: 2.2958  last_time: 2.6302  data_time: 0.0700  last_data_time: 0.1192   lr: 0.00025  max_mem: 8864M\n","[03/19 07:40:24 d2.utils.events]:  eta: 0:39:41  iter: 939  total_loss: 1.234  loss_cls: 0.2951  loss_box_reg: 0.4905  loss_mask: 0.2809  loss_rpn_cls: 0.04102  loss_rpn_loc: 0.129    time: 2.2955  last_time: 2.2237  data_time: 0.0647  last_data_time: 0.0308   lr: 0.00025  max_mem: 8864M\n","[03/19 07:41:10 d2.utils.events]:  eta: 0:38:57  iter: 959  total_loss: 1.187  loss_cls: 0.2934  loss_box_reg: 0.4716  loss_mask: 0.2727  loss_rpn_cls: 0.03424  loss_rpn_loc: 0.1176    time: 2.2962  last_time: 2.6570  data_time: 0.0643  last_data_time: 0.0346   lr: 0.00025  max_mem: 8864M\n","[03/19 07:41:56 d2.utils.events]:  eta: 0:38:13  iter: 979  total_loss: 1.198  loss_cls: 0.2817  loss_box_reg: 0.473  loss_mask: 0.2771  loss_rpn_cls: 0.03664  loss_rpn_loc: 0.1178    time: 2.2962  last_time: 2.1765  data_time: 0.0645  last_data_time: 0.0715   lr: 0.00025  max_mem: 8864M\n","[03/19 07:42:46 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[03/19 07:42:46 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/19 07:42:46 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n","[03/19 07:42:46 d2.data.common]: Serialized dataset takes 0.04 MiB\n","[03/19 07:42:46 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n","WARNING [03/19 07:42:46 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[03/19 07:42:46 d2.evaluation.evaluator]: Start inference on 5 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 07:42:47 d2.evaluation.evaluator]: Total inference time: 0:00:00.238480 (0.238480 s / iter per device, on 1 devices)\n","[03/19 07:42:47 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:00 (0.093746 s / iter per device, on 1 devices)\n","[03/19 07:42:47 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[03/19 07:42:47 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/inference/coco_instances_results.json\n","[03/19 07:42:47 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.10s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.705\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.363\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.576\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:42:47 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 35.712 | 70.497 | 32.587 | 28.323 | 44.726 |  nan  |\n","[03/19 07:42:47 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.09s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.236\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.189\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.388\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:42:47 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 36.131 | 75.465 | 31.312 | 23.572 | 45.912 |  nan  |\n","[03/19 07:42:47 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[03/19 07:42:47 d2.engine.defaults]: Evaluation results for tree_valid in csv format:\n","[03/19 07:42:47 d2.evaluation.testing]: copypaste: Task: bbox\n","[03/19 07:42:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:42:47 d2.evaluation.testing]: copypaste: 35.7118,70.4972,32.5872,28.3227,44.7258,nan\n","[03/19 07:42:47 d2.evaluation.testing]: copypaste: Task: segm\n","[03/19 07:42:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:42:47 d2.evaluation.testing]: copypaste: 36.1308,75.4652,31.3116,23.5723,45.9115,nan\n","[03/19 07:42:47 d2.utils.events]:  eta: 0:37:30  iter: 999  total_loss: 1.233  loss_cls: 0.3006  loss_box_reg: 0.4868  loss_mask: 0.2764  loss_rpn_cls: 0.04001  loss_rpn_loc: 0.1237    time: 2.2976  last_time: 2.4206  data_time: 0.0555  last_data_time: 0.0710   lr: 0.00025  max_mem: 8864M\n","[03/19 07:43:35 d2.utils.events]:  eta: 0:36:48  iter: 1019  total_loss: 1.213  loss_cls: 0.291  loss_box_reg: 0.4726  loss_mask: 0.2825  loss_rpn_cls: 0.03727  loss_rpn_loc: 0.123    time: 2.2992  last_time: 2.2509  data_time: 0.0694  last_data_time: 0.0783   lr: 0.00025  max_mem: 8864M\n","[03/19 07:44:21 d2.utils.events]:  eta: 0:36:06  iter: 1039  total_loss: 1.195  loss_cls: 0.3001  loss_box_reg: 0.4776  loss_mask: 0.2741  loss_rpn_cls: 0.03876  loss_rpn_loc: 0.1189    time: 2.2996  last_time: 2.2976  data_time: 0.0596  last_data_time: 0.0799   lr: 0.00025  max_mem: 8864M\n","[03/19 07:45:07 d2.utils.events]:  eta: 0:35:21  iter: 1059  total_loss: 1.203  loss_cls: 0.2909  loss_box_reg: 0.4798  loss_mask: 0.2727  loss_rpn_cls: 0.04025  loss_rpn_loc: 0.1197    time: 2.2998  last_time: 2.1489  data_time: 0.0594  last_data_time: 0.0606   lr: 0.00025  max_mem: 8864M\n","[03/19 07:45:53 d2.utils.events]:  eta: 0:34:36  iter: 1079  total_loss: 1.197  loss_cls: 0.2882  loss_box_reg: 0.4805  loss_mask: 0.2729  loss_rpn_cls: 0.03559  loss_rpn_loc: 0.1234    time: 2.2994  last_time: 2.4523  data_time: 0.0665  last_data_time: 0.0619   lr: 0.00025  max_mem: 8864M\n","[03/19 07:46:40 d2.utils.events]:  eta: 0:33:56  iter: 1099  total_loss: 1.21  loss_cls: 0.2971  loss_box_reg: 0.4757  loss_mask: 0.2706  loss_rpn_cls: 0.03468  loss_rpn_loc: 0.1174    time: 2.3005  last_time: 2.3897  data_time: 0.0591  last_data_time: 0.0534   lr: 0.00025  max_mem: 8864M\n","[03/19 07:47:27 d2.utils.events]:  eta: 0:33:13  iter: 1119  total_loss: 1.175  loss_cls: 0.2808  loss_box_reg: 0.4688  loss_mask: 0.2731  loss_rpn_cls: 0.04404  loss_rpn_loc: 0.1366    time: 2.3013  last_time: 2.8759  data_time: 0.0572  last_data_time: 0.0228   lr: 0.00025  max_mem: 8864M\n","[03/19 07:48:13 d2.utils.events]:  eta: 0:32:28  iter: 1139  total_loss: 1.207  loss_cls: 0.2852  loss_box_reg: 0.4786  loss_mask: 0.2754  loss_rpn_cls: 0.03946  loss_rpn_loc: 0.1254    time: 2.3011  last_time: 2.2188  data_time: 0.0573  last_data_time: 0.0545   lr: 0.00025  max_mem: 8864M\n","[03/19 07:48:59 d2.utils.events]:  eta: 0:31:40  iter: 1159  total_loss: 1.181  loss_cls: 0.2764  loss_box_reg: 0.4661  loss_mask: 0.2728  loss_rpn_cls: 0.04048  loss_rpn_loc: 0.1294    time: 2.3014  last_time: 2.6959  data_time: 0.0606  last_data_time: 0.1302   lr: 0.00025  max_mem: 8864M\n","[03/19 07:49:45 d2.utils.events]:  eta: 0:30:54  iter: 1179  total_loss: 1.187  loss_cls: 0.2867  loss_box_reg: 0.4704  loss_mask: 0.2675  loss_rpn_cls: 0.03741  loss_rpn_loc: 0.1227    time: 2.3010  last_time: 2.2983  data_time: 0.0639  last_data_time: 0.0518   lr: 0.00025  max_mem: 8864M\n","[03/19 07:50:31 d2.utils.events]:  eta: 0:30:10  iter: 1199  total_loss: 1.178  loss_cls: 0.2823  loss_box_reg: 0.4701  loss_mask: 0.2713  loss_rpn_cls: 0.03529  loss_rpn_loc: 0.1211    time: 2.3008  last_time: 2.1768  data_time: 0.0562  last_data_time: 0.0664   lr: 0.00025  max_mem: 8864M\n","[03/19 07:51:17 d2.utils.events]:  eta: 0:29:26  iter: 1219  total_loss: 1.204  loss_cls: 0.2876  loss_box_reg: 0.465  loss_mask: 0.2705  loss_rpn_cls: 0.03222  loss_rpn_loc: 0.125    time: 2.3012  last_time: 2.2844  data_time: 0.0613  last_data_time: 0.0225   lr: 0.00025  max_mem: 8864M\n","[03/19 07:52:04 d2.utils.events]:  eta: 0:28:38  iter: 1239  total_loss: 1.163  loss_cls: 0.2825  loss_box_reg: 0.4589  loss_mask: 0.2705  loss_rpn_cls: 0.0376  loss_rpn_loc: 0.1219    time: 2.3018  last_time: 2.2702  data_time: 0.0607  last_data_time: 0.0236   lr: 0.00025  max_mem: 8864M\n","[03/19 07:52:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[03/19 07:52:27 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/19 07:52:27 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n","[03/19 07:52:27 d2.data.common]: Serialized dataset takes 0.04 MiB\n","[03/19 07:52:27 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n","WARNING [03/19 07:52:27 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[03/19 07:52:27 d2.evaluation.evaluator]: Start inference on 5 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 07:52:28 d2.evaluation.evaluator]: Total inference time: 0:00:00.231918 (0.231918 s / iter per device, on 1 devices)\n","[03/19 07:52:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:00 (0.090569 s / iter per device, on 1 devices)\n","[03/19 07:52:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[03/19 07:52:28 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/inference/coco_instances_results.json\n","[03/19 07:52:28 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.09s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.725\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.333\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.289\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.182\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.365\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:52:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 36.069 | 72.507 | 33.311 | 28.893 | 44.814 |  nan  |\n","[03/19 07:52:28 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.09s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.331\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.369\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 07:52:28 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 36.103 | 73.859 | 33.088 | 22.856 | 46.355 |  nan  |\n","[03/19 07:52:28 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[03/19 07:52:28 d2.engine.defaults]: Evaluation results for tree_valid in csv format:\n","[03/19 07:52:28 d2.evaluation.testing]: copypaste: Task: bbox\n","[03/19 07:52:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:52:28 d2.evaluation.testing]: copypaste: 36.0692,72.5073,33.3109,28.8926,44.8136,nan\n","[03/19 07:52:28 d2.evaluation.testing]: copypaste: Task: segm\n","[03/19 07:52:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 07:52:28 d2.evaluation.testing]: copypaste: 36.1027,73.8594,33.0881,22.8558,46.3553,nan\n","[03/19 07:52:51 d2.utils.events]:  eta: 0:27:53  iter: 1259  total_loss: 1.183  loss_cls: 0.2878  loss_box_reg: 0.4698  loss_mask: 0.2733  loss_rpn_cls: 0.03408  loss_rpn_loc: 0.1179    time: 2.3019  last_time: 2.1674  data_time: 0.0727  last_data_time: 0.0874   lr: 0.00025  max_mem: 8864M\n","[03/19 07:53:37 d2.utils.events]:  eta: 0:27:08  iter: 1279  total_loss: 1.147  loss_cls: 0.28  loss_box_reg: 0.4593  loss_mask: 0.2713  loss_rpn_cls: 0.03423  loss_rpn_loc: 0.1142    time: 2.3018  last_time: 2.1718  data_time: 0.0574  last_data_time: 0.0341   lr: 0.00025  max_mem: 8864M\n","[03/19 07:54:24 d2.utils.events]:  eta: 0:26:22  iter: 1299  total_loss: 1.166  loss_cls: 0.2767  loss_box_reg: 0.4626  loss_mask: 0.2666  loss_rpn_cls: 0.03379  loss_rpn_loc: 0.1226    time: 2.3020  last_time: 2.2141  data_time: 0.0657  last_data_time: 0.0225   lr: 0.00025  max_mem: 8864M\n","[03/19 07:55:10 d2.utils.events]:  eta: 0:25:39  iter: 1319  total_loss: 1.153  loss_cls: 0.2773  loss_box_reg: 0.4671  loss_mask: 0.2719  loss_rpn_cls: 0.03508  loss_rpn_loc: 0.1156    time: 2.3025  last_time: 2.3625  data_time: 0.0709  last_data_time: 0.0531   lr: 0.00025  max_mem: 8864M\n","[03/19 07:55:58 d2.utils.events]:  eta: 0:24:55  iter: 1339  total_loss: 1.153  loss_cls: 0.2784  loss_box_reg: 0.4645  loss_mask: 0.2674  loss_rpn_cls: 0.03318  loss_rpn_loc: 0.1194    time: 2.3037  last_time: 2.7675  data_time: 0.0633  last_data_time: 0.0769   lr: 0.00025  max_mem: 8864M\n","[03/19 07:56:45 d2.utils.events]:  eta: 0:24:11  iter: 1359  total_loss: 1.173  loss_cls: 0.2788  loss_box_reg: 0.4543  loss_mask: 0.266  loss_rpn_cls: 0.03498  loss_rpn_loc: 0.1335    time: 2.3042  last_time: 2.3530  data_time: 0.0613  last_data_time: 0.0713   lr: 0.00025  max_mem: 8864M\n","[03/19 07:57:31 d2.utils.events]:  eta: 0:23:25  iter: 1379  total_loss: 1.172  loss_cls: 0.2711  loss_box_reg: 0.4579  loss_mask: 0.2681  loss_rpn_cls: 0.03302  loss_rpn_loc: 0.1166    time: 2.3045  last_time: 2.6435  data_time: 0.0595  last_data_time: 0.1148   lr: 0.00025  max_mem: 8864M\n","[03/19 07:58:17 d2.utils.events]:  eta: 0:22:41  iter: 1399  total_loss: 1.169  loss_cls: 0.2781  loss_box_reg: 0.4732  loss_mask: 0.2683  loss_rpn_cls: 0.02903  loss_rpn_loc: 0.1196    time: 2.3042  last_time: 2.3259  data_time: 0.0695  last_data_time: 0.0444   lr: 0.00025  max_mem: 8864M\n","[03/19 07:59:03 d2.utils.events]:  eta: 0:21:56  iter: 1419  total_loss: 1.135  loss_cls: 0.2675  loss_box_reg: 0.4563  loss_mask: 0.2655  loss_rpn_cls: 0.03253  loss_rpn_loc: 0.1164    time: 2.3044  last_time: 2.5810  data_time: 0.0550  last_data_time: 0.0794   lr: 0.00025  max_mem: 8864M\n","[03/19 07:59:49 d2.utils.events]:  eta: 0:21:10  iter: 1439  total_loss: 1.177  loss_cls: 0.2835  loss_box_reg: 0.4625  loss_mask: 0.2685  loss_rpn_cls: 0.03081  loss_rpn_loc: 0.1161    time: 2.3044  last_time: 2.2409  data_time: 0.0591  last_data_time: 0.0712   lr: 0.00025  max_mem: 8864M\n","[03/19 08:00:35 d2.utils.events]:  eta: 0:20:25  iter: 1459  total_loss: 1.183  loss_cls: 0.2815  loss_box_reg: 0.4622  loss_mask: 0.2688  loss_rpn_cls: 0.03474  loss_rpn_loc: 0.1242    time: 2.3042  last_time: 2.4009  data_time: 0.0765  last_data_time: 0.0451   lr: 0.00025  max_mem: 8864M\n","[03/19 08:01:21 d2.utils.events]:  eta: 0:19:40  iter: 1479  total_loss: 1.141  loss_cls: 0.2701  loss_box_reg: 0.4609  loss_mask: 0.2645  loss_rpn_cls: 0.0323  loss_rpn_loc: 0.1141    time: 2.3040  last_time: 2.0235  data_time: 0.0620  last_data_time: 0.0661   lr: 0.00025  max_mem: 8864M\n","[03/19 08:02:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[03/19 08:02:07 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/19 08:02:07 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n","[03/19 08:02:07 d2.data.common]: Serialized dataset takes 0.04 MiB\n","[03/19 08:02:07 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n","WARNING [03/19 08:02:07 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[03/19 08:02:07 d2.evaluation.evaluator]: Start inference on 5 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 08:02:09 d2.evaluation.evaluator]: Total inference time: 0:00:00.338197 (0.338197 s / iter per device, on 1 devices)\n","[03/19 08:02:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:00 (0.091487 s / iter per device, on 1 devices)\n","[03/19 08:02:09 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[03/19 08:02:09 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/inference/coco_instances_results.json\n","[03/19 08:02:09 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.19s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.359\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.702\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.355\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.280\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.181\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.365\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 08:02:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 35.895 | 70.218 | 35.536 | 28.042 | 45.189 |  nan  |\n","[03/19 08:02:09 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.17s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.181\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.393\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 08:02:09 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 36.220 | 74.892 | 32.797 | 23.988 | 45.088 |  nan  |\n","[03/19 08:02:09 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[03/19 08:02:09 d2.engine.defaults]: Evaluation results for tree_valid in csv format:\n","[03/19 08:02:09 d2.evaluation.testing]: copypaste: Task: bbox\n","[03/19 08:02:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 08:02:09 d2.evaluation.testing]: copypaste: 35.8948,70.2175,35.5357,28.0416,45.1895,nan\n","[03/19 08:02:09 d2.evaluation.testing]: copypaste: Task: segm\n","[03/19 08:02:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 08:02:09 d2.evaluation.testing]: copypaste: 36.2199,74.8923,32.7973,23.9882,45.0883,nan\n","[03/19 08:02:09 d2.utils.events]:  eta: 0:18:55  iter: 1499  total_loss: 1.129  loss_cls: 0.2751  loss_box_reg: 0.4494  loss_mask: 0.2611  loss_rpn_cls: 0.03322  loss_rpn_loc: 0.1143    time: 2.3040  last_time: 2.3244  data_time: 0.0627  last_data_time: 0.0738   lr: 0.00025  max_mem: 8864M\n","[03/19 08:02:56 d2.utils.events]:  eta: 0:18:10  iter: 1519  total_loss: 1.18  loss_cls: 0.2892  loss_box_reg: 0.4632  loss_mask: 0.2661  loss_rpn_cls: 0.03022  loss_rpn_loc: 0.121    time: 2.3047  last_time: 2.1474  data_time: 0.0603  last_data_time: 0.0635   lr: 0.00025  max_mem: 8864M\n","[03/19 08:03:42 d2.utils.events]:  eta: 0:17:24  iter: 1539  total_loss: 1.152  loss_cls: 0.2763  loss_box_reg: 0.4535  loss_mask: 0.2645  loss_rpn_cls: 0.03308  loss_rpn_loc: 0.117    time: 2.3047  last_time: 2.3220  data_time: 0.0699  last_data_time: 0.0657   lr: 0.00025  max_mem: 8864M\n","[03/19 08:04:29 d2.utils.events]:  eta: 0:16:39  iter: 1559  total_loss: 1.174  loss_cls: 0.2799  loss_box_reg: 0.4698  loss_mask: 0.2631  loss_rpn_cls: 0.03424  loss_rpn_loc: 0.1331    time: 2.3050  last_time: 2.2152  data_time: 0.0654  last_data_time: 0.0422   lr: 0.00025  max_mem: 8864M\n","[03/19 08:05:15 d2.utils.events]:  eta: 0:15:53  iter: 1579  total_loss: 1.159  loss_cls: 0.2708  loss_box_reg: 0.4499  loss_mask: 0.265  loss_rpn_cls: 0.03405  loss_rpn_loc: 0.1197    time: 2.3051  last_time: 2.2456  data_time: 0.0623  last_data_time: 0.0565   lr: 0.00025  max_mem: 8864M\n","[03/19 08:06:01 d2.utils.events]:  eta: 0:15:08  iter: 1599  total_loss: 1.162  loss_cls: 0.273  loss_box_reg: 0.4623  loss_mask: 0.2631  loss_rpn_cls: 0.03317  loss_rpn_loc: 0.1213    time: 2.3053  last_time: 2.2921  data_time: 0.0610  last_data_time: 0.0580   lr: 0.00025  max_mem: 8864M\n","[03/19 08:06:47 d2.utils.events]:  eta: 0:14:22  iter: 1619  total_loss: 1.153  loss_cls: 0.2644  loss_box_reg: 0.4479  loss_mask: 0.2676  loss_rpn_cls: 0.03473  loss_rpn_loc: 0.1227    time: 2.3052  last_time: 2.2065  data_time: 0.0614  last_data_time: 0.0407   lr: 0.00025  max_mem: 8864M\n","[03/19 08:07:34 d2.utils.events]:  eta: 0:13:38  iter: 1639  total_loss: 1.127  loss_cls: 0.2714  loss_box_reg: 0.4473  loss_mask: 0.2665  loss_rpn_cls: 0.03113  loss_rpn_loc: 0.1158    time: 2.3057  last_time: 2.3240  data_time: 0.0589  last_data_time: 0.0511   lr: 0.00025  max_mem: 8864M\n","[03/19 08:08:20 d2.utils.events]:  eta: 0:12:53  iter: 1659  total_loss: 1.14  loss_cls: 0.2647  loss_box_reg: 0.456  loss_mask: 0.2633  loss_rpn_cls: 0.03341  loss_rpn_loc: 0.1187    time: 2.3055  last_time: 2.2027  data_time: 0.0604  last_data_time: 0.0497   lr: 0.00025  max_mem: 8864M\n","[03/19 08:09:07 d2.utils.events]:  eta: 0:12:08  iter: 1679  total_loss: 1.15  loss_cls: 0.2693  loss_box_reg: 0.4588  loss_mask: 0.2688  loss_rpn_cls: 0.03177  loss_rpn_loc: 0.1185    time: 2.3060  last_time: 2.7546  data_time: 0.0579  last_data_time: 0.0806   lr: 0.00025  max_mem: 8864M\n","[03/19 08:09:54 d2.utils.events]:  eta: 0:11:23  iter: 1699  total_loss: 1.142  loss_cls: 0.2704  loss_box_reg: 0.4537  loss_mask: 0.2633  loss_rpn_cls: 0.03071  loss_rpn_loc: 0.1201    time: 2.3063  last_time: 2.0675  data_time: 0.0702  last_data_time: 0.0767   lr: 0.00025  max_mem: 8864M\n","[03/19 08:10:40 d2.utils.events]:  eta: 0:10:38  iter: 1719  total_loss: 1.146  loss_cls: 0.2752  loss_box_reg: 0.4558  loss_mask: 0.263  loss_rpn_cls: 0.03205  loss_rpn_loc: 0.111    time: 2.3065  last_time: 2.6057  data_time: 0.0689  last_data_time: 0.0458   lr: 0.00025  max_mem: 8864M\n","[03/19 08:11:26 d2.utils.events]:  eta: 0:09:51  iter: 1739  total_loss: 1.123  loss_cls: 0.2643  loss_box_reg: 0.4481  loss_mask: 0.258  loss_rpn_cls: 0.03162  loss_rpn_loc: 0.1195    time: 2.3061  last_time: 2.2275  data_time: 0.0576  last_data_time: 0.0507   lr: 0.00025  max_mem: 8864M\n","[03/19 08:11:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[03/19 08:11:49 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/19 08:11:49 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n","[03/19 08:11:49 d2.data.common]: Serialized dataset takes 0.04 MiB\n","[03/19 08:11:49 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n","WARNING [03/19 08:11:49 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[03/19 08:11:49 d2.evaluation.evaluator]: Start inference on 5 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 08:11:50 d2.evaluation.evaluator]: Total inference time: 0:00:00.224942 (0.224942 s / iter per device, on 1 devices)\n","[03/19 08:11:50 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:00 (0.090377 s / iter per device, on 1 devices)\n","[03/19 08:11:50 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[03/19 08:11:50 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/inference/coco_instances_results.json\n","[03/19 08:11:50 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.09s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.695\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.335\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.266\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.176\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 08:11:50 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 34.349 | 69.502 | 33.477 | 26.584 | 43.515 |  nan  |\n","[03/19 08:11:50 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.09s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.721\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.185\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.369\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 08:11:50 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 35.326 | 72.123 | 30.265 | 22.888 | 44.579 |  nan  |\n","[03/19 08:11:50 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[03/19 08:11:50 d2.engine.defaults]: Evaluation results for tree_valid in csv format:\n","[03/19 08:11:50 d2.evaluation.testing]: copypaste: Task: bbox\n","[03/19 08:11:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 08:11:50 d2.evaluation.testing]: copypaste: 34.3487,69.5016,33.4770,26.5837,43.5153,nan\n","[03/19 08:11:50 d2.evaluation.testing]: copypaste: Task: segm\n","[03/19 08:11:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 08:11:50 d2.evaluation.testing]: copypaste: 35.3265,72.1235,30.2647,22.8878,44.5790,nan\n","[03/19 08:12:13 d2.utils.events]:  eta: 0:09:06  iter: 1759  total_loss: 1.188  loss_cls: 0.2733  loss_box_reg: 0.4612  loss_mask: 0.2665  loss_rpn_cls: 0.03754  loss_rpn_loc: 0.1226    time: 2.3060  last_time: 2.5895  data_time: 0.0613  last_data_time: 0.0425   lr: 0.00025  max_mem: 8864M\n","[03/19 08:12:59 d2.utils.events]:  eta: 0:08:20  iter: 1779  total_loss: 1.127  loss_cls: 0.2658  loss_box_reg: 0.4474  loss_mask: 0.2598  loss_rpn_cls: 0.03248  loss_rpn_loc: 0.117    time: 2.3060  last_time: 2.2211  data_time: 0.0537  last_data_time: 0.0330   lr: 0.00025  max_mem: 8864M\n","[03/19 08:13:46 d2.utils.events]:  eta: 0:07:35  iter: 1799  total_loss: 1.143  loss_cls: 0.2716  loss_box_reg: 0.4478  loss_mask: 0.262  loss_rpn_cls: 0.03127  loss_rpn_loc: 0.1193    time: 2.3065  last_time: 2.5649  data_time: 0.0680  last_data_time: 0.0861   lr: 0.00025  max_mem: 8864M\n","[03/19 08:14:32 d2.utils.events]:  eta: 0:06:50  iter: 1819  total_loss: 1.115  loss_cls: 0.2638  loss_box_reg: 0.4467  loss_mask: 0.2621  loss_rpn_cls: 0.03084  loss_rpn_loc: 0.1124    time: 2.3062  last_time: 2.0593  data_time: 0.0600  last_data_time: 0.0800   lr: 0.00025  max_mem: 8864M\n","[03/19 08:15:18 d2.utils.events]:  eta: 0:06:04  iter: 1839  total_loss: 1.118  loss_cls: 0.2603  loss_box_reg: 0.4466  loss_mask: 0.2555  loss_rpn_cls: 0.03038  loss_rpn_loc: 0.1141    time: 2.3062  last_time: 2.1610  data_time: 0.0703  last_data_time: 0.0296   lr: 0.00025  max_mem: 8864M\n","[03/19 08:16:04 d2.utils.events]:  eta: 0:05:19  iter: 1859  total_loss: 1.133  loss_cls: 0.2665  loss_box_reg: 0.4485  loss_mask: 0.261  loss_rpn_cls: 0.03369  loss_rpn_loc: 0.1165    time: 2.3061  last_time: 2.2178  data_time: 0.0591  last_data_time: 0.0347   lr: 0.00025  max_mem: 8864M\n","[03/19 08:16:49 d2.utils.events]:  eta: 0:04:33  iter: 1879  total_loss: 1.128  loss_cls: 0.2703  loss_box_reg: 0.4414  loss_mask: 0.2597  loss_rpn_cls: 0.03184  loss_rpn_loc: 0.1201    time: 2.3058  last_time: 2.3054  data_time: 0.0595  last_data_time: 0.0627   lr: 0.00025  max_mem: 8864M\n","[03/19 08:17:36 d2.utils.events]:  eta: 0:03:47  iter: 1899  total_loss: 1.102  loss_cls: 0.2593  loss_box_reg: 0.438  loss_mask: 0.2572  loss_rpn_cls: 0.03163  loss_rpn_loc: 0.118    time: 2.3060  last_time: 2.5214  data_time: 0.0623  last_data_time: 0.0366   lr: 0.00025  max_mem: 8864M\n","[03/19 08:18:23 d2.utils.events]:  eta: 0:03:02  iter: 1919  total_loss: 1.113  loss_cls: 0.2598  loss_box_reg: 0.4497  loss_mask: 0.2606  loss_rpn_cls: 0.03013  loss_rpn_loc: 0.1079    time: 2.3063  last_time: 2.1626  data_time: 0.0627  last_data_time: 0.0811   lr: 0.00025  max_mem: 8864M\n","[03/19 08:19:09 d2.utils.events]:  eta: 0:02:16  iter: 1939  total_loss: 1.115  loss_cls: 0.2673  loss_box_reg: 0.4331  loss_mask: 0.2618  loss_rpn_cls: 0.03051  loss_rpn_loc: 0.1176    time: 2.3063  last_time: 2.7104  data_time: 0.0649  last_data_time: 0.0979   lr: 0.00025  max_mem: 8864M\n","[03/19 08:19:55 d2.utils.events]:  eta: 0:01:31  iter: 1959  total_loss: 1.091  loss_cls: 0.2632  loss_box_reg: 0.4415  loss_mask: 0.2587  loss_rpn_cls: 0.02984  loss_rpn_loc: 0.1067    time: 2.3063  last_time: 2.3168  data_time: 0.0622  last_data_time: 0.0580   lr: 0.00025  max_mem: 8864M\n","[03/19 08:20:40 d2.utils.events]:  eta: 0:00:45  iter: 1979  total_loss: 1.094  loss_cls: 0.2671  loss_box_reg: 0.4405  loss_mask: 0.2597  loss_rpn_cls: 0.02849  loss_rpn_loc: 0.1103    time: 2.3059  last_time: 2.0860  data_time: 0.0571  last_data_time: 0.0380   lr: 0.00025  max_mem: 8864M\n","[03/19 08:21:29 d2.utils.events]:  eta: 0:00:00  iter: 1999  total_loss: 1.07  loss_cls: 0.2584  loss_box_reg: 0.4377  loss_mask: 0.2556  loss_rpn_cls: 0.03009  loss_rpn_loc: 0.1104    time: 2.3059  last_time: 2.2319  data_time: 0.0593  last_data_time: 0.0540   lr: 0.00025  max_mem: 8864M\n","[03/19 08:21:29 d2.engine.hooks]: Overall training speed: 1998 iterations in 1:16:47 (2.3059 s / it)\n","[03/19 08:21:29 d2.engine.hooks]: Total training time: 1:17:12 (0:00:25 on hooks)\n","[03/19 08:21:29 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[03/19 08:21:29 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/19 08:21:29 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n","[03/19 08:21:29 d2.data.common]: Serialized dataset takes 0.04 MiB\n","[03/19 08:21:29 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n","WARNING [03/19 08:21:29 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[03/19 08:21:29 d2.evaluation.evaluator]: Start inference on 5 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[03/19 08:21:30 d2.evaluation.evaluator]: Total inference time: 0:00:00.226375 (0.226375 s / iter per device, on 1 devices)\n","[03/19 08:21:30 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:00 (0.088725 s / iter per device, on 1 devices)\n","[03/19 08:21:30 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[03/19 08:21:30 d2.evaluation.coco_evaluation]: Saving results to /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/inference/coco_instances_results.json\n","[03/19 08:21:30 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.09s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.722\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.274\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.178\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 08:21:30 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 34.673 | 72.205 | 31.811 | 27.383 | 43.691 |  nan  |\n","[03/19 08:21:30 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.09s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.310\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.236\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.183\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.381\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","[03/19 08:21:30 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n","|:------:|:------:|:------:|:------:|:------:|:-----:|\n","| 36.266 | 74.823 | 31.023 | 23.648 | 45.825 |  nan  |\n","[03/19 08:21:30 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[03/19 08:21:30 d2.engine.defaults]: Evaluation results for tree_valid in csv format:\n","[03/19 08:21:30 d2.evaluation.testing]: copypaste: Task: bbox\n","[03/19 08:21:30 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 08:21:30 d2.evaluation.testing]: copypaste: 34.6729,72.2049,31.8106,27.3835,43.6905,nan\n","[03/19 08:21:30 d2.evaluation.testing]: copypaste: Task: segm\n","[03/19 08:21:30 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[03/19 08:21:30 d2.evaluation.testing]: copypaste: 36.2664,74.8229,31.0228,23.6476,45.8251,nan\n","[03/19 08:21:31 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/model_final.pth ...\n","✅ Training complete. Model loaded for inference.\n"]}],"source":["import os\n","import detectron2.data.transforms as T\n","from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","from detectron2.model_zoo import get_config_file\n","from detectron2.evaluation import COCOEvaluator\n","from detectron2.engine import DefaultPredictor\n","from detectron2.data import DatasetMapper, build_detection_train_loader\n","\n","# Set output directory\n","MODEL_DIR = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)\"\n","INFERENCE_DIR = os.path.join(MODEL_DIR, \"inference\")\n","os.makedirs(MODEL_DIR, exist_ok=True)\n","os.makedirs(INFERENCE_DIR, exist_ok=True)\n","\n","# Load configuration\n","cfg = get_cfg()\n","cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","\n","# Update configuration\n","cfg.DATASETS.TRAIN = (\"tree_train\",)\n","cfg.DATASETS.TEST = (\"tree_valid\",)\n","cfg.DATALOADER.NUM_WORKERS = 4  # Increased for better parallel data loading\n","\n","cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # 1 class (tree)\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n","\n","# Solver settings\n","cfg.SOLVER.IMS_PER_BATCH = 8  # Increased batch size\n","cfg.SOLVER.BASE_LR = 0.00025\n","cfg.SOLVER.WARMUP_FACTOR = 0.001\n","cfg.SOLVER.WARMUP_ITERS = 100\n","cfg.SOLVER.MAX_ITER = 2000  # Increased training iterations for better learning\n","cfg.SOLVER.STEPS = []  # No LR decay\n","cfg.SOLVER.CHECKPOINT_PERIOD = 1000  # Save model every 1000 iterations\n","\n","# Evaluation settings\n","cfg.TEST.EVAL_PERIOD = 250  # Evaluate every 250 iterations\n","\n","# Set output directory\n","cfg.OUTPUT_DIR = MODEL_DIR\n","\n","# Custom trainer class to include validation and augmentation\n","class CustomTrainer(DefaultTrainer):\n","    @classmethod\n","    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","        return COCOEvaluator(dataset_name, cfg, False, INFERENCE_DIR)\n","\n","    @classmethod\n","    def build_train_loader(cls, cfg):\n","        return build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=[\n","            T.RandomFlip(horizontal=True, vertical=False),\n","            T.RandomFlip(horizontal=False, vertical=True),\n","            T.RandomRotation(angle=[-10, 10]),\n","            T.RandomBrightness(0.8, 1.2),\n","            T.RandomContrast(0.8, 1.2),\n","            T.RandomSaturation(0.8, 1.2),\n","            T.RandomExtent(scale_range=(0.8, 1.2), shift_range=(0.1, 0.1))  # Fixed\n","        ]))\n","\n","# Train model\n","trainer = CustomTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()\n","\n","# Load trained model for inference\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","predictor = DefaultPredictor(cfg)\n","\n","print(\"✅ Training complete. Model loaded for inference.\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7279,"status":"ok","timestamp":1742372509269,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"f4WSDEhIChsI","outputId":"c0dd00be-39bc-4e28-9c7e-b127e4814655"},"outputs":[{"output_type":"stream","name":"stdout","text":["[03/19 08:21:42 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/model_final.pth ...\n","✅ Binary masks saved successfully!\n"]}],"source":["import torch\n","import numpy as np\n","import cv2\n","import os\n","from detectron2.engine import DefaultPredictor\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog\n","from detectron2.structures import Instances\n","\n","# Load trained model\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold for prediction\n","predictor = DefaultPredictor(cfg)\n","\n","# Set paths\n","BINARY_MASK_DIR = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Final images\"\n","os.makedirs(BINARY_MASK_DIR, exist_ok=True)\n","\n","def generate_binary_mask(image_path, save_path):\n","    image = cv2.imread(image_path)\n","    outputs = predictor(image)\n","\n","    instances = outputs[\"instances\"]\n","    if len(instances) == 0:\n","        print(f\"No detections in {image_path}\")\n","        return\n","\n","    # Get the segmentation masks\n","    masks = instances.pred_masks.to(\"cpu\").numpy()\n","\n","    # Combine all masks into a single binary mask\n","    binary_mask = np.any(masks, axis=0).astype(np.uint8) * 255\n","\n","    # Apply morphological closing to refine mask\n","    kernel = np.ones((5,5), np.uint8)\n","    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n","\n","    # Save binary mask\n","    cv2.imwrite(save_path, binary_mask)\n","\n","# Process all test images\n","TEST_IMAGES_DIR = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/test\"\n","test_images = os.listdir(TEST_IMAGES_DIR)\n","\n","for img_name in test_images:\n","    img_path = os.path.join(TEST_IMAGES_DIR, img_name)\n","    save_path = os.path.join(BINARY_MASK_DIR, f\"mask_{img_name}\")\n","    generate_binary_mask(img_path, save_path)\n","\n","print(\"✅ Binary masks saved successfully!\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5401,"status":"ok","timestamp":1742367732659,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"HCzstUDpNZZK","outputId":"83abef08-f765-46c6-c629-494290b3c417"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rasterio\n","  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n","Collecting affine (from rasterio)\n","  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n","Collecting cligj>=0.5 (from rasterio)\n","  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n","Collecting click-plugins (from rasterio)\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.1)\n","Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m209.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n","Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Installing collected packages: cligj, click-plugins, affine, rasterio\n","Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"]}],"source":["!pip install --no-cache-dir --upgrade rasterio"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4088,"status":"ok","timestamp":1742372516809,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"PU6gLfYSNOBD","outputId":"f69de8b3-0df4-4c5c-80b6-1340e1de78aa"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/rasterio/__init__.py:366: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n","  dataset = writer(\n"]},{"output_type":"stream","name":"stdout","text":["✅ `.tif` and `.jpg` saved successfully!\n"]}],"source":["import rasterio\n","from rasterio.windows import Window\n","from PIL import Image\n","import numpy as np\n","import cv2\n","from detectron2.engine import DefaultPredictor\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog\n","from detectron2.structures import Instances\n","\n","# Set input/output paths\n","TIF_FILE = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/vadasan.tif\"\n","OUTPUT_TIF = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Combined/final_mask.tif\"\n","OUTPUT_JPG = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Combined/final_mask.jpg\"\n","\n","# Read .tif file\n","with rasterio.open(TIF_FILE) as src:\n","    width, height = src.width, src.height\n","    tile_size = 1024  # Split into 1024x1024 chunks\n","\n","    stitched_mask = np.zeros((height, width), dtype=np.uint8)\n","\n","    for i in range(0, width, tile_size):\n","        for j in range(0, height, tile_size):\n","            # Ensure tile stays within image bounds\n","            w = min(tile_size, width - i)\n","            h = min(tile_size, height - j)\n","\n","            window = Window(i, j, w, h)\n","            image_tile = src.read(window=window).transpose(1, 2, 0)  # Convert to HxWxC\n","\n","            # Ensure 3-channel RGB format (convert if needed)\n","            if image_tile.shape[-1] == 4:  # Convert RGBA → RGB\n","                image_tile = image_tile[:, :, :3]\n","            elif image_tile.shape[-1] == 1:  # Grayscale → RGB\n","                image_tile = np.repeat(image_tile, 3, axis=-1)\n","\n","            # Convert to BGR (OpenCV format)\n","            image_tile = cv2.cvtColor(image_tile, cv2.COLOR_RGB2BGR)\n","\n","            # Convert NumPy image to uint8\n","            image_tile = image_tile.astype(np.uint8)\n","\n","            # Run Mask R-CNN\n","            outputs = predictor(image_tile)  # ⬅️ Keep it as NumPy, do not convert to tensor\n","            instances = outputs[\"instances\"]\n","\n","            if len(instances) > 0:\n","                masks = instances.pred_masks.to(\"cpu\").numpy()\n","                binary_mask = np.any(masks, axis=0).astype(np.uint8) * 255\n","\n","                # Store result in the correct region of stitched_mask\n","                stitched_mask[j:j+h, i:i+w] = binary_mask[:h, :w]\n","\n","# Save as .tif\n","with rasterio.open(\n","    OUTPUT_TIF, 'w',\n","    driver=\"GTiff\", height=height, width=width,\n","    count=1, dtype=rasterio.uint8\n",") as dst:\n","    dst.write(stitched_mask, 1)\n","\n","# Save as .jpg\n","Image.fromarray(stitched_mask).save(OUTPUT_JPG)\n","\n","print(\"✅ `.tif` and `.jpg` saved successfully!\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1208,"status":"ok","timestamp":1742372520810,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"6UhDclCMaSzV","outputId":"d860ea2e-22b4-4f18-e6e6-2669251b6f40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_15_jpg.rf.a01fab9918ceba352e30292e52faf62e.jpg, mask not found.\n","Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_13_jpg.rf.67527b46d1658dc3746f9ba55317b1ff.jpg, mask not found.\n","Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_29_jpg.rf.994b96f79767a3d412f175e187c9d70c.jpg, mask not found.\n","Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_3_jpg.rf.afb50919ca59abf604375c41e26e4ad6.jpg, mask not found.\n","Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_6_jpg.rf.2dd06e14814d8307516937c7ed06de7a.jpg, mask not found.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n","  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["✅ TIF Overlay saved!\n","✅ Overlay process complete!\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","import rasterio\n","\n","# Set paths\n","ROOT_DIR = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)\"\n","TEST_FOLDER = os.path.join(ROOT_DIR, \"Test\")\n","FINAL_IMAGES_FOLDER = os.path.join(ROOT_DIR, \"Final images\")\n","COMBINED_FOLDER = os.path.join(ROOT_DIR, \"Combined\")\n","OVERLAY_FOLDER = os.path.join(ROOT_DIR, \"Overlay\")\n","\n","# Ensure overlay folder exists\n","os.makedirs(OVERLAY_FOLDER, exist_ok=True)\n","\n","# Function to count trees using contours\n","def count_trees(binary_mask):\n","    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    return len(contours)\n","\n","# Function to overlay mask on image\n","def overlay_mask(image_path, mask_path, output_path):\n","    image = cv2.imread(image_path)\n","    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","\n","    if image is None or mask is None:\n","        print(f\"Skipping {image_path}, mask not found.\")\n","        return\n","\n","    # Convert mask to binary\n","    binary_mask = (mask > 0).astype(np.uint8) * 255\n","\n","    # Count trees\n","    tree_count = count_trees(binary_mask)\n","\n","    # Overlay mask in red while keeping original colors\n","    red_mask = np.zeros_like(image)\n","    red_mask[:, :, 2] = binary_mask  # Apply only to red channel\n","    overlay = cv2.addWeighted(image, 0.7, red_mask, 0.3, 0)\n","\n","    # Add tree count text at top-left\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    cv2.putText(overlay, f'Trees: {tree_count}', (10, 50), font, 1, (0, 0, 255), 2, cv2.LINE_AA)\n","\n","    # Save output\n","    cv2.imwrite(output_path, overlay)\n","\n","# Process .jpg images (Final images + Test)\n","for mask_file in os.listdir(FINAL_IMAGES_FOLDER):\n","    image_file = mask_file.replace(\"_mask\", \"\")  # Adjust name mapping if necessary\n","    image_path = os.path.join(TEST_FOLDER, image_file)\n","    mask_path = os.path.join(FINAL_IMAGES_FOLDER, mask_file)\n","    output_path = os.path.join(OVERLAY_FOLDER, image_file)\n","\n","    overlay_mask(image_path, mask_path, output_path)\n","\n","# Process .tif image (Combined folder)\n","TIF_FILE = os.path.join(ROOT_DIR, \"vadasan.tif\")\n","COMBINED_MASK = os.path.join(COMBINED_FOLDER, \"final_mask.tif\")\n","OUTPUT_TIF = os.path.join(OVERLAY_FOLDER, \"final_overlay.tif\")\n","\n","if os.path.exists(COMBINED_MASK):\n","    with rasterio.open(TIF_FILE) as src:\n","        image = src.read([1, 2, 3]).transpose(1, 2, 0)  # Read RGB channels\n","        mask = rasterio.open(COMBINED_MASK).read(1)  # Read mask as grayscale\n","\n","        # Convert image to uint8 format\n","        image = (image / image.max() * 255).astype(np.uint8)\n","\n","        # Convert mask to binary\n","        binary_mask = (mask > 0).astype(np.uint8) * 255\n","\n","        # Count trees\n","        tree_count = count_trees(binary_mask)\n","\n","        # Create a red transparent overlay\n","        red_mask = np.zeros_like(image)\n","        red_mask[:, :, 2] = binary_mask  # Apply only to red channel\n","        overlay = cv2.addWeighted(image, 0.7, red_mask, 0.3, 0)\n","\n","        # Add tree count text\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        cv2.putText(overlay, f'Trees: {tree_count}', (10, 50), font, 2, (0, 0, 255), 5, cv2.LINE_AA)\n","\n","        # Save as .tif\n","        with rasterio.open(\n","            OUTPUT_TIF, \"w\",\n","            driver=\"GTiff\", height=overlay.shape[0], width=overlay.shape[1],\n","            count=3, dtype=rasterio.uint8\n","        ) as dst:\n","            for i in range(3):\n","                dst.write(overlay[:, :, i], i + 1)\n","\n","    print(\"✅ TIF Overlay saved!\")\n","\n","print(\"✅ Overlay process complete!\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1652,"status":"ok","timestamp":1742372528501,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"},"user_tz":-330},"id":"K8HdenwLi1Hz","outputId":"cd45223e-cd20-449d-d5ad-b3e40ed9e64f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_15_jpg.rf.a01fab9918ceba352e30292e52faf62e.jpg, mask not found.\n","Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_13_jpg.rf.67527b46d1658dc3746f9ba55317b1ff.jpg, mask not found.\n","Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_29_jpg.rf.994b96f79767a3d412f175e187c9d70c.jpg, mask not found.\n","Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_3_jpg.rf.afb50919ca59abf604375c41e26e4ad6.jpg, mask not found.\n","Skipping /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Test/mask_chunk_6_jpg.rf.2dd06e14814d8307516937c7ed06de7a.jpg, mask not found.\n","✅ TIF Overlay saved!\n","✅ Overlay process complete!\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","import rasterio\n","\n","# Set paths\n","ROOT_DIR = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)\"\n","TEST_FOLDER = os.path.join(ROOT_DIR, \"Test\")\n","FINAL_IMAGES_FOLDER = os.path.join(ROOT_DIR, \"Final images\")\n","COMBINED_FOLDER = os.path.join(ROOT_DIR, \"Combined\")\n","OVERLAY_FOLDER = os.path.join(ROOT_DIR, \"Overlay\")\n","\n","# Ensure overlay folder exists\n","os.makedirs(OVERLAY_FOLDER, exist_ok=True)\n","\n","# Function to count trees using the Canopy Method\n","def count_trees_canopy(binary_mask):\n","    \"\"\"Counts trees using Distance Transform & Watershed segmentation.\"\"\"\n","    # Apply Gaussian Blur to smooth small noise\n","    blurred = cv2.GaussianBlur(binary_mask, (5, 5), 0)\n","\n","    # Apply threshold to enhance tree canopies\n","    _, thresh = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n","\n","    # Distance Transform (Find tree centers)\n","    dist_transform = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)\n","\n","    # Normalize the distance transform for visualization\n","    cv2.normalize(dist_transform, dist_transform, 0, 1.0, cv2.NORM_MINMAX)\n","\n","    # Threshold to get tree centers\n","    _, tree_centers = cv2.threshold(dist_transform, 0.3, 1.0, cv2.THRESH_BINARY)\n","    tree_centers = (tree_centers * 255).astype(np.uint8)\n","\n","    # Find contours (each representing a tree canopy)\n","    contours, _ = cv2.findContours(tree_centers, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    return len(contours)  # Number of detected trees\n","\n","# Function to overlay mask on image\n","def overlay_mask(image_path, mask_path, output_path):\n","    image = cv2.imread(image_path)\n","    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","\n","    if image is None or mask is None:\n","        print(f\"Skipping {image_path}, mask not found.\")\n","        return\n","\n","    # Convert mask to binary\n","    binary_mask = (mask > 0).astype(np.uint8) * 255\n","\n","    # Count trees using Canopy Method\n","    tree_count = count_trees_canopy(binary_mask)\n","\n","    # Overlay mask in red while keeping original colors\n","    red_mask = np.zeros_like(image)\n","    red_mask[:, :, 2] = binary_mask  # Apply only to red channel\n","    overlay = cv2.addWeighted(image, 0.7, red_mask, 0.3, 0)\n","\n","    # Add tree count text at top-left\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    cv2.putText(overlay, f'Trees: {tree_count}', (10, 50), font, 1, (0, 0, 255), 2, cv2.LINE_AA)\n","\n","    # Save output\n","    cv2.imwrite(output_path, overlay)\n","\n","# Process .jpg images (Final images + Test)\n","for mask_file in os.listdir(FINAL_IMAGES_FOLDER):\n","    image_file = mask_file.replace(\"_mask\", \"\")  # Adjust name mapping if necessary\n","    image_path = os.path.join(TEST_FOLDER, image_file)\n","    mask_path = os.path.join(FINAL_IMAGES_FOLDER, mask_file)\n","    output_path = os.path.join(OVERLAY_FOLDER, image_file)\n","\n","    overlay_mask(image_path, mask_path, output_path)\n","\n","# Process .tif image (Combined folder)\n","TIF_FILE = os.path.join(ROOT_DIR, \"vadasan.tif\")\n","COMBINED_MASK = os.path.join(COMBINED_FOLDER, \"final_mask.tif\")\n","OUTPUT_TIF = os.path.join(OVERLAY_FOLDER, \"final_overlay_canopy.tif\")\n","\n","if os.path.exists(COMBINED_MASK):\n","    with rasterio.open(TIF_FILE) as src:\n","        image = src.read([1, 2, 3]).transpose(1, 2, 0)  # Read RGB channels\n","        mask = rasterio.open(COMBINED_MASK).read(1)  # Read mask as grayscale\n","\n","        # Convert image to uint8 format\n","        image = (image / image.max() * 255).astype(np.uint8)\n","\n","        # Convert mask to binary\n","        binary_mask = (mask > 0).astype(np.uint8) * 255\n","\n","        # Count trees using Canopy Method\n","        tree_count = count_trees_canopy(binary_mask)\n","\n","        # Create a red transparent overlay\n","        red_mask = np.zeros_like(image)\n","        red_mask[:, :, 2] = binary_mask  # Apply only to red channel\n","        overlay = cv2.addWeighted(image, 0.7, red_mask, 0.3, 0)\n","\n","        # Add tree count text\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        cv2.putText(overlay, f'Trees: {tree_count}', (10, 50), font, 2, (0, 0, 255), 5, cv2.LINE_AA)\n","\n","        # Save as .tif\n","        with rasterio.open(\n","            OUTPUT_TIF, \"w\",\n","            driver=\"GTiff\", height=overlay.shape[0], width=overlay.shape[1],\n","            count=3, dtype=rasterio.uint8\n","        ) as dst:\n","            for i in range(3):\n","                dst.write(overlay[:, :, i], i + 1)\n","\n","    print(\"✅ TIF Overlay saved!\")\n","\n","print(\"✅ Overlay process complete!\")"]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import rasterio\n","import geopandas as gpd\n","from rasterio.transform import from_origin\n","from shapely.geometry import Polygon\n","\n","# Set paths\n","ROOT_DIR = \"/content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)\"\n","TIF_PATH = os.path.join(ROOT_DIR, \"vadasan.tif\")\n","MASK_PATH = os.path.join(ROOT_DIR, \"Combined\", \"final_mask.tif\")\n","SHAPEFILE_DIR = os.path.join(ROOT_DIR, \"Shapefiles\")\n","SHAPEFILE_PATH = os.path.join(SHAPEFILE_DIR, \"final_trees.shp\")\n","\n","# Ensure output folder exists\n","os.makedirs(SHAPEFILE_DIR, exist_ok=True)\n","\n","# Load mask\n","with rasterio.open(MASK_PATH) as mask_src:\n","    mask = mask_src.read(1)  # Read first band (grayscale)\n","    mask = (mask > 0).astype(np.uint8) * 255  # Convert to binary\n","\n","# Extract tree contours\n","contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","# Load original TIF to get georeferencing info\n","with rasterio.open(TIF_PATH) as tif_src:\n","    transform = tif_src.transform  # Get spatial transform\n","    crs = tif_src.crs  # Get coordinate reference system\n","\n","# Convert contours to geospatial polygons\n","def convert_to_geo_polygon(contour, transform):\n","    \"\"\"Convert image-based contour to a georeferenced polygon.\"\"\"\n","    coords = []\n","    for point in contour:\n","        img_x, img_y = point[0]  # Image coordinates\n","        geo_x, geo_y = rasterio.transform.xy(transform, img_y, img_x)  # Convert to geographic coords\n","        coords.append((geo_x, geo_y))\n","    return Polygon(coords)\n","\n","# Create polygons for detected trees\n","polygons = [convert_to_geo_polygon(cnt, transform) for cnt in contours]\n","\n","# Create GeoDataFrame\n","gdf = gpd.GeoDataFrame({\"tree_count\": list(range(1, len(polygons) + 1))}, geometry=polygons, crs=crs)\n","\n","# Save as Shapefile\n","gdf.to_file(SHAPEFILE_PATH, driver=\"ESRI Shapefile\")\n","\n","print(f\"✅ Shapefile saved at: {SHAPEFILE_PATH}\")\n","print(f\"🌳 Total Trees Detected: {len(polygons)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwjNlWhrjeMF","executionInfo":{"status":"ok","timestamp":1742372535911,"user_tz":-330,"elapsed":4861,"user":{"displayName":"Divyansh Chavda","userId":"00101923338614770253"}},"outputId":"24df2d46-5d82-4e41-822a-69a7c08de038"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Shapefile saved at: /content/drive/MyDrive/Tree Dataset (Augmentation + Fine Tuned) (Mask R-CNN Canopy) (Vadasan)/Shapefiles/final_trees.shp\n","🌳 Total Trees Detected: 369\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}