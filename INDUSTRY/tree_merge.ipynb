{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Detection whole mask code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import math\n",
    "import glob\n",
    "import fiona\n",
    "import torch\n",
    "import random\n",
    "import tifffile\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from fiona.crs import from_epsg\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.features import shapes\n",
    "from rasterio.transform import from_origin\n",
    "from shapely.geometry import shape, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = r\"D:\\BISAG-N\\VADASAN\\YOLOv11\\phase-3\"\n",
    "main_tif_path = os.path.join(main_folder,\"D:/BISAG-N/VADASAN/vadasan.tif\")\n",
    "output_subregions_folder = os.path.join(main_folder,\"cropped\") # Cropped Output\n",
    "subregion_size=640\n",
    "\n",
    "input_dir_containing_jpg = output_subregions_folder # Cropped JPG images\n",
    "output_dir_containing_jpg = os.path.join(main_folder,\"predicted_yolov11s_phase_3\") # Output Binary predicted images\n",
    "model_path = r\"D:\\BISAG-N\\VADASAN\\YOLOv11\\phase-3\\best (16).pt\" # path to the Model\n",
    "\n",
    "merged_predicted_image_path=os.path.join(main_folder,\"mergeyolov11s_phase-3.jpg\") # Merged Predicted Image Directory path\n",
    "\n",
    "border_width = 4\n",
    "\n",
    "georeferenced_image_path = os.path.join(main_folder,\"geo_merged_yolov11s_phase-3.tif\")\n",
    "vector_shape_file_path = os.path.join(main_folder,\"vector_merged_yolov11s_phase-3.shp\")\n",
    "\n",
    "pixel_resolution=0.05 #In Meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_subregions_folder,exist_ok=True)\n",
    "os.makedirs(output_dir_containing_jpg, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subregions(input_path, output_folder, subregion_size):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    image = tifffile.imread(input_path)\n",
    "    height, width = image.shape[:2]\n",
    "    subregion_count = 1\n",
    "\n",
    "    for y in range(0, height, subregion_size):\n",
    "        for x in range(0, width, subregion_size):\n",
    "            top = y\n",
    "            left = x\n",
    "\n",
    "            bottom = min(y + subregion_size, height)\n",
    "            right = min(x + subregion_size, width)\n",
    "\n",
    "            subregion = image[top:bottom, left:right]\n",
    "\n",
    "            # Add padding if necessary\n",
    "            if bottom - top < subregion_size or right - left < subregion_size:\n",
    "                padded_subregion = np.zeros((subregion_size, subregion_size, image.shape[2]), dtype=image.dtype)\n",
    "                padded_subregion[:bottom-top, :right-left] = subregion\n",
    "                subregion = padded_subregion\n",
    "\n",
    "            # Save without metadata\n",
    "            output_path = os.path.join(output_folder, f\"{subregion_count}.tif\")\n",
    "            tifffile.imwrite(output_path, subregion, metadata=None)\n",
    "            subregion_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tif_to_jpg(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith('.tif'):\n",
    "            tif_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(tif_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                \n",
    "                jpg_path = os.path.join(folder_path, os.path.splitext(filename)[0] + '.jpg')\n",
    "                \n",
    "                img.save(jpg_path, 'JPEG', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tif_files(folder_path):\n",
    "    # Use glob to find all .tif files in the specified folder\n",
    "    tif_files = glob.glob(os.path.join(folder_path, \"*.tif\"))\n",
    "    \n",
    "    # Loop through the list of .tif files and delete each one\n",
    "    for tif_file in tif_files:\n",
    "        try:\n",
    "            os.remove(tif_file)\n",
    "            # print(f\"Deleted: {tif_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {tif_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    os.makedirs(output_dir_containing_jpg, exist_ok=True)\n",
    "\n",
    "\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_dir_containing_jpg) if os.path.isfile(os.path.join(input_dir_containing_jpg, f)) and f.lower().endswith('.jpg')]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img_path = os.path.join(input_dir_containing_jpg, image_file)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        results = list(model.predict(source=img.copy(), save=False, save_txt=False, stream=True, show_boxes=False, conf=0.2,verbose=False))\n",
    "\n",
    "        if results[0] is None or len(results[0]) == 0:  # If no detections found\n",
    "            black_image = np.zeros_like(img)\n",
    "            output_path = os.path.join(output_dir_containing_jpg, f'{os.path.splitext(image_file)[0]}.jpg')\n",
    "            cv2.imwrite(output_path, black_image)\n",
    "        else:\n",
    "            for result in results:\n",
    "                masks = result.masks.data\n",
    "                boxes = result.boxes.data\n",
    "\n",
    "                clss = boxes[:, 5]\n",
    "    \n",
    "                people_indices = torch.where(clss == 0)\n",
    "\n",
    "                people_masks = masks[people_indices]\n",
    "\n",
    "                people_mask = torch.any(people_masks, dim=0).int() * 255\n",
    "\n",
    "                output_path = os.path.join(output_dir_containing_jpg, f'{os.path.splitext(image_file)[0]}.jpg')    \n",
    "                cv2.imwrite(output_path, people_mask.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_border_pixels(image_path, output_path, border_width):\n",
    "  img = Image.open(image_path)\n",
    "  width, height = img.size\n",
    "\n",
    "  # Validate image size and border width\n",
    "  if border_width * 2 >= width or border_width * 2 >= height:\n",
    "    raise ValueError(f\"Border width ({border_width}) cannot be more than half the image dimensions.\")\n",
    "\n",
    "  pixels = img.load()\n",
    "\n",
    "  # Replace top pixels\n",
    "  for x in range(width):\n",
    "    for y in range(border_width):\n",
    "      new_pixel_value = pixels[x, border_width + y]\n",
    "      pixels[x, y] = new_pixel_value\n",
    "\n",
    "  # Replace bottom pixels (reversed order)\n",
    "  for x in range(width):\n",
    "    for y in range(height - border_width, height):\n",
    "      new_pixel_value = pixels[x, y - border_width - 1]\n",
    "      pixels[x, y] = new_pixel_value\n",
    "\n",
    "  # Replace left pixels\n",
    "  for y in range(height):\n",
    "    for x in range(border_width):\n",
    "      new_pixel_value = pixels[border_width + x, y]\n",
    "      pixels[x, y] = new_pixel_value\n",
    "\n",
    "  # Replace right pixels (reversed order)\n",
    "  for y in range(height):\n",
    "    for x in range(width - border_width, width):\n",
    "      new_pixel_value = pixels[x - border_width - 1, y]\n",
    "      pixels[x, y] = new_pixel_value\n",
    "\n",
    "  # Save the modified image\n",
    "  img.save(output_path)\n",
    "\n",
    "def process_folder(folder_path, output_folder_path, border_width):\n",
    "\n",
    "\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "      image_path = os.path.join(folder_path, filename)\n",
    "      output_path = os.path.join(output_folder_path, filename) if output_folder_path else image_path\n",
    "      try:\n",
    "        replace_border_pixels(image_path, output_path, border_width)\n",
    "        # print(f\"Processed image: {filename}\")\n",
    "      except ValueError as e:\n",
    "        print(f\"Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_tiles(width, height):\n",
    "  \n",
    "  num_tiles_x = math.ceil(width / subregion_size)\n",
    "  num_tiles_y = math.ceil(height / subregion_size)\n",
    "  print(num_tiles_x,num_tiles_y)\n",
    "  return num_tiles_x, num_tiles_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(image_folder, output_image_path, rows, cols):\n",
    "    image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.jpg')], key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    image_paths = [os.path.join(image_folder, f) for f in image_files]\n",
    "\n",
    "    if len(image_paths) < rows * cols:\n",
    "        raise ValueError(\"Not enough images to fill the grid.\")\n",
    "    # print(image_paths)\n",
    "\n",
    "    images = [np.array(Image.open(img_path).convert('RGB')) for img_path in image_paths[:rows * cols]]\n",
    "    \n",
    "    img_height, img_width, img_channels = images[0].shape\n",
    "\n",
    "    merged_image_array = np.zeros((rows * img_height, cols * img_width, img_channels), dtype=np.uint8)\n",
    "\n",
    "    for index, img in enumerate(images):\n",
    "        # print(img)\n",
    "        row = index // cols\n",
    "        col = index % cols\n",
    "        merged_image_array[row * img_height:(row + 1) * img_height, col * img_width:(col + 1) * img_width, :] = img\n",
    "\n",
    "    merged_image = Image.fromarray(merged_image_array)\n",
    "    \n",
    "    merged_image.save(output_image_path)\n",
    "\n",
    "    print(f\"Merged image saved to {output_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image_path, crop_width, crop_height, output_path=None):\n",
    "    image = Image.open(image_path)\n",
    "    width, height = image.size\n",
    "    crop_area = (0, 0, width - crop_width, height - crop_height)\n",
    "    cropped_image = image.crop(crop_area)\n",
    "    if output_path is None:\n",
    "        output_path = image_path\n",
    "    cropped_image.save(output_path)\n",
    "    \n",
    "    print(f'Cropped image saved as {output_path} with dimensions {cropped_image.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(image_path):\n",
    "  try:\n",
    "    # Try Pillow (PIL Fork) first\n",
    "    from PIL import Image\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "    return width, height\n",
    "\n",
    "  except (OSError, IOError):\n",
    "    # If Pillow fails, try OpenCV\n",
    "    import cv2\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "      return None\n",
    "    height, width = img.shape[:2]\n",
    "    return width, height\n",
    "\n",
    "  except ImportError:\n",
    "    # Handle case where neither library is installed\n",
    "    print(\"Error: Please install Pillow or OpenCV library.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_georeferencing_info(tif_path):\n",
    "    with rasterio.open(tif_path) as dataset:\n",
    "        transform = dataset.transform\n",
    "        crs = dataset.crs\n",
    "    return transform, crs\n",
    "\n",
    "# Function to georeference a JPG image\n",
    "def geo_reference_jpg(jpg_path, output_tif_path, transform, crs):\n",
    "    # Read the JPG image\n",
    "    img = cv2.imread(jpg_path)\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    # Create a new rasterio dataset\n",
    "    new_transform = from_origin(transform.c, transform.f, transform.a, -transform.e)\n",
    "    with rasterio.open(\n",
    "        output_tif_path, 'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=channels,\n",
    "        dtype=img.dtype,\n",
    "        crs=crs,\n",
    "        transform=new_transform,\n",
    "    ) as dst:\n",
    "        for i in range(1, channels + 1):\n",
    "            dst.write(img[:, :, i - 1], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_to_vector(georeferenced_image_path, vector_shape_file_path, threshold_value=240):\n",
    "    with rasterio.open(georeferenced_image_path) as src:\n",
    "        raster = src.read(1)  # Read the first band\n",
    "        transform = src.transform\n",
    "        raster_crs = src.crs  # Get the CRS of the raster\n",
    "\n",
    "    threshold_value = 128\n",
    "    binary_raster = (raster > threshold_value).astype(np.uint8)\n",
    "\n",
    "    shapes_generator = shapes(binary_raster, transform=transform)\n",
    "    polygons = []\n",
    "    for geom, value in shapes_generator:\n",
    "        if value == 1:\n",
    "            polygons.append(shape(geom))\n",
    "\n",
    "    output_path = vector_shape_file_path\n",
    "\n",
    "    crs_epsg_code = 3857  \n",
    "\n",
    "    schema = {\n",
    "        'geometry': 'Polygon',\n",
    "        'properties': {'id': 'int'},\n",
    "    }\n",
    "\n",
    "    crs = from_epsg(crs_epsg_code)  \n",
    "    with fiona.open(output_path, 'w', driver='ESRI Shapefile', schema=schema, crs=crs) as shp:\n",
    "        for i, polygon in enumerate(polygons):\n",
    "            shp.write({\n",
    "                'geometry': mapping(polygon),\n",
    "                'properties': {'id': i},\n",
    "            })\n",
    "\n",
    "    print(f\"Vector file saved at: {vector_shape_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4\n",
      "Merged image saved to D:\\BISAG-N\\VADASAN\\YOLOv11\\phase-3\\mergeyolov11s_phase-3.jpg\n",
      "Cropped image saved as D:\\BISAG-N\\VADASAN\\YOLOv11\\phase-3\\mergeyolov11s_phase-3.jpg with dimensions (3111, 2238)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16248\\2040773147.py:13: FionaDeprecationWarning: This function will be removed in version 2.0. Please use CRS.from_epsg() instead.\n",
      "  raster_to_vector(georeferenced_image_path, vector_shape_file_path, threshold_value=240)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector file saved at: D:\\BISAG-N\\VADASAN\\YOLOv11\\phase-3\\vector_merged_yolov11s_phase-3.shp\n"
     ]
    }
   ],
   "source": [
    "extract_subregions(main_tif_path, output_subregions_folder, subregion_size)\n",
    "convert_tif_to_jpg(output_subregions_folder)\n",
    "delete_tif_files(output_subregions_folder)\n",
    "predict()\n",
    "process_folder(output_dir_containing_jpg, output_dir_containing_jpg, border_width)\n",
    "width_tif, height_tif = get_image_size(main_tif_path)\n",
    "columns, rows = get_num_tiles(width_tif, height_tif)\n",
    "merge_images(image_folder=output_dir_containing_jpg, output_image_path=merged_predicted_image_path, rows=rows, cols=columns)\n",
    "width_jpg, height_jpg = get_image_size(merged_predicted_image_path)\n",
    "crop_image(merged_predicted_image_path, width_jpg-width_tif, height_jpg-height_tif,merged_predicted_image_path)\n",
    "transform, crs = get_georeferencing_info(main_tif_path)\n",
    "geo_reference_jpg(merged_predicted_image_path, georeferenced_image_path, transform, crs)\n",
    "raster_to_vector(georeferenced_image_path, vector_shape_file_path, threshold_value=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
